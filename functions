1. Linear Regression (FASTEST)
from sklearn.linear_model import LinearRegression
reg = LinearRegression()

2. Ridge Regression (L2 regularized, stable)
from sklearn.linear_model import Ridge
reg = Ridge(alpha=1.0)

3. Lasso Regression (L1 sparse model)
from sklearn.linear_model import Lasso
reg = Lasso(alpha=0.001)

4. ElasticNet (mix of L1 + L2)
from sklearn.linear_model import ElasticNet
reg = ElasticNet(alpha=0.001, l1_ratio=0.5)

5. KNN Regressor (small K) â€” simple & very stable
from sklearn.neighbors import KNeighborsRegressor
reg = KNeighborsRegressor(n_neighbors=3)

6. DecisionTreeRegressor (single tree, very lightweight)
from sklearn.tree import DecisionTreeRegressor
reg = DecisionTreeRegressor(max_depth=5)

7. SGDRegressor (linear model optimized via SGD)
from sklearn.linear_model import SGDRegressor
reg = SGDRegressor(max_iter=500, learning_rate="adaptive")

 
Super-safe recommended choice

The best trade-off between speed and stability is:

from sklearn.linear_model import Ridge
reg = Ridge(alpha=1.0)


It works extremely well for vector prediction without blowing memory.

Fixed final code example (safe & stable)
import numpy as np
from sklearn.linear_model import Ridge
from flowmatching_bdt_modified import FlowMatchingBDT

# Training data
X = np.random.randn(300, 4)
conditions = np.random.randint(0, 3, size=(300, 1))

# Very lightweight regressor
reg = Ridge(alpha=1.0)

model = FlowMatchingBDT(
    base_regressor=reg,
    n_flow_steps=20,      # also reduces memory
    n_duplicates=20       # also reduces memory
)

model.fit(X, conditions)

generated = model.predict(50, conditions=np.zeros((50, 1)))

print(generated.shape)
